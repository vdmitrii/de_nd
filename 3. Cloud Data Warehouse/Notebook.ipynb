{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Load DWH Params from a file\n",
    "\n",
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "config.read_file(open('dwh.cfg'))\n",
    "\n",
    "KEY                    = config.get('AWS','KEY')\n",
    "SECRET                 = config.get('AWS','SECRET')\n",
    "\n",
    "CLUSTER_TYPE       = config.get(\"CLUSTER\",\"CLUSTER_TYPE\")\n",
    "NUM_NODES          = config.get(\"CLUSTER\",\"NUM_NODES\")\n",
    "NODE_TYPE          = config.get(\"CLUSTER\",\"NODE_TYPE\")\n",
    "\n",
    "CLUSTER_IDENTIFIER = config.get(\"CLUSTER\",\"CLUSTER_IDENTIFIER\")\n",
    "DB_NAME            = config.get(\"CLUSTER\",\"DB_NAME\")\n",
    "DB_USER            = config.get(\"CLUSTER\",\"DB_USER\")\n",
    "DB_PASSWORD        = config.get(\"CLUSTER\",\"DB_PASSWORD\")\n",
    "PORT               = config.get(\"CLUSTER\",\"DB_PORT\")\n",
    "REGION             = config.get(\"CLUSTER\",\"REGION\")\n",
    "IAM_ROLE_NAME      = config.get(\"CLUSTER\",\"IAM_ROLE_NAME\")\n",
    "ARN                = config.get(\"IAM_ROLE\", \"ARN\")\n",
    "\n",
    "(DB_USER, DB_PASSWORD, DB_NAME)\n",
    "\n",
    "pd.DataFrame({\"Param\":\n",
    "                  [\"CLUSTER_TYPE\", \"NUM_NODES\", \"DNODE_TYPE\", \"CLUSTER_IDENTIFIER\", \"DB_NAME\", \"DB_USER\", \"DB_PASSWORD\", \"PORT\", \"IAM_ROLE_NAME\", \"REGION\", \"ARN\"],\n",
    "              \"Value\":\n",
    "                  [CLUSTER_TYPE, NUM_NODES, NODE_TYPE, CLUSTER_IDENTIFIER, DB_NAME, DB_USER, DB_PASSWORD, PORT, IAM_ROLE_NAME, REGION, ARN]\n",
    "             })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create clients for EC2, S3, IAM, and Redshift\n",
    "\n",
    "# s3 = boto3.resource('s3',\n",
    "#                        region_name = REGION,\n",
    "#                        aws_access_key_id = KEY,\n",
    "#                        aws_secret_access_key = SECRET\n",
    "#                    )\n",
    "\n",
    "iam = boto3.client('iam',aws_access_key_id = KEY,\n",
    "                     aws_secret_access_key = SECRET,\n",
    "                     region_name = REGION\n",
    "                  )\n",
    "\n",
    "redshift = boto3.client('redshift',\n",
    "                       region_name = REGION,\n",
    "                       aws_access_key_id=KEY,\n",
    "                       aws_secret_access_key=SECRET\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create an IAM Role that makes Redshift able to access S3 bucket (ReadOnly)\n",
    "\n",
    "try:\n",
    "    print('1.1 Creating a new IAM Role')\n",
    "    dwhRole = iam.create_role(\n",
    "        Path='/',\n",
    "        RoleName=IAM_ROLE_NAME,\n",
    "        Description = \"Allows Redshift clusters to call AWS services on your behalf.\",\n",
    "        AssumeRolePolicyDocument=json.dumps(\n",
    "            {'Statement': [{'Action': 'sts:AssumeRole',\n",
    "               'Effect': 'Allow',\n",
    "               'Principal': {'Service': 'redshift.amazonaws.com'}}],\n",
    "             'Version': '2012-10-17'})\n",
    "    )    \n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    dwhRole = iam.get_role(RoleName=IAM_ROLE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#  Attaching Policy\n",
    "\n",
    "print('1.2 Attaching Policy')\n",
    "iam.attach_role_policy(RoleName=IAM_ROLE_NAME,\n",
    "                       PolicyArn=\"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\"\n",
    "                      )['ResponseMetadata']['HTTPStatusCode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Get the Role ARN\n",
    "\n",
    "print('1.3 Get the IAM role ARN')\n",
    "roleArn = iam.get_role(RoleName=IAM_ROLE_NAME)['Role']['Arn']\n",
    "\n",
    "print(roleArn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create a RedShift Cluster\n",
    "\n",
    "try:\n",
    "    response = redshift.create_cluster(        \n",
    "        #HW\n",
    "        ClusterType = CLUSTER_TYPE,\n",
    "        NodeType = NODE_TYPE,\n",
    "        NumberOfNodes = int(NUM_NODES),\n",
    "\n",
    "        #Identifiers & Credentials\n",
    "        DBName = DB_NAME,\n",
    "        ClusterIdentifier = CLUSTER_IDENTIFIER,\n",
    "        MasterUsername = DB_USER,\n",
    "        MasterUserPassword = DB_PASSWORD,\n",
    "        \n",
    "        #Roles (for s3 access)\n",
    "        IamRoles = [roleArn]\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Describe the cluster to see its status\n",
    "\n",
    "def prettyRedshiftProps(props):\n",
    "    pd.set_option('display.max_colwidth', -1)\n",
    "    keysToShow = [\"ClusterIdentifier\", \"NodeType\", \"ClusterStatus\", \"MasterUsername\", \"DBName\", \"Endpoint\", \"NumberOfNodes\", 'VpcId']\n",
    "    x = [(k, v) for k,v in props.items() if k in keysToShow]\n",
    "    return pd.DataFrame(data=x, columns=[\"Key\", \"Value\"])\n",
    "\n",
    "myClusterProps = redshift.describe_clusters(ClusterIdentifier=CLUSTER_IDENTIFIER)['Clusters'][0]\n",
    "prettyRedshiftProps(myClusterProps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Cluster status is 'available'?\n",
    "\n",
    "redshift.describe_clusters(ClusterIdentifier=CLUSTER_IDENTIFIER)['Clusters'][0][\"ClusterStatus\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Take note of the cluster endpoint and role ARN\n",
    "\n",
    "ENDPOINT = myClusterProps['Endpoint']['Address']\n",
    "IAM_ROLE_ARN = myClusterProps['IamRoles'][0]['IamRoleArn']\n",
    "print(\"ENDPOINT :: \", ENDPOINT)\n",
    "print(\"IAM_ROLE_ARN :: \", IAM_ROLE_ARN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Make sure you can connect to the clusterConnect to the cluster and run a few queries\n",
    "\n",
    "%load_ext sql\n",
    "\n",
    "conn_string = f\"postgresql://{DB_USER}:{DB_PASSWORD}@{ENDPOINT}:{PORT}/{DB_NAME}\"\n",
    "print(conn_string)\n",
    "%sql $conn_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Execute ETL on cluster\n",
    "%run etl.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create all tables\n",
    "%run create_tables.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Number of rows in events staging table\n",
    "\n",
    "cur.execute(\"SELECT COUNT(*) FROM events_staging\")\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Number of rows in songs staging table\n",
    "\n",
    "cur.execute(\"SELECT COUNT(*) FROM songs_staging\")\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Delete the created resources\n",
    "redshift.delete_cluster( ClusterIdentifier=DWH_CLUSTER_IDENTIFIER,  SkipFinalClusterSnapshot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Delete the created resources\n",
    "\n",
    "iam.detach_role_policy(RoleName=DWH_IAM_ROLE_NAME, PolicyArn=\"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\")\n",
    "iam.delete_role(RoleName=DWH_IAM_ROLE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
